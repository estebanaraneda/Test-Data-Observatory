{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base de modulos y funciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def standardise_column_names(df, remove_punct=True):\n",
    "    \"\"\" Converts all DataFrame column names to lower case replacing\n",
    "    whitespace of any length with a single underscore. Can also strip\n",
    "    all punctuation from column names.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pandas.DataFrame\n",
    "        DataFrame with non-standardised column names.\n",
    "    remove_punct: bool (default True)\n",
    "        If True will remove all punctuation from column names.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df: pandas.DataFrame\n",
    "        DataFrame with standardised column names.\n",
    "    Example\n",
    "    -------\n",
    "    >>> df = pd.DataFrame({'Column With Spaces': [1,2,3,4,5],\n",
    "                           'Column-With-Hyphens&Others/': [6,7,8,9,10],\n",
    "                           'Too    Many Spaces': [11,12,13,14,15],\n",
    "                           })\n",
    "    >>> df = standardise_column_names(df)\n",
    "    >>> print(df.columns)\n",
    "    Index(['column_with_spaces',\n",
    "           'column_with_hyphens_others',\n",
    "           'too_many_spaces'], dtype='object')\n",
    "    \"\"\"\n",
    "\n",
    "    translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
    "\n",
    "    for c in df.columns:\n",
    "        c_mod = c.lower()\n",
    "        if remove_punct:\n",
    "            c_mod = c_mod.translate(translator)\n",
    "        c_mod = '_'.join(c_mod.split(' '))\n",
    "        if c_mod[-1] == '_':\n",
    "            c_mod = c_mod[:-1]\n",
    "        c_mod = re.sub(r'\\_+', '_', c_mod)\n",
    "        df.rename({c: c_mod}, inplace=True, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos el archivo\n",
    "df = pd.read_csv('crucero_1.csv', header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos filas y columnas vacias\n",
    "df = df.dropna(axis=0, how='all')\n",
    "df = df.dropna(axis=1, how='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos formato fecha\n",
    "df['yyyy-mm-ddThh:mm:ss.sss'] = df['yyyy-mm-ddThh:mm:ss.sss'].apply(pd.to_datetime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenamos vacios con datos de filas superiores\n",
    "df = df.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             cruise  station type yyyy_mm_ddthh_mm_ss_sss  \\\n",
      "0      Crucero 2016     37.0    C     2016-10-25 12:10:00   \n",
      "1      Crucero 2016     37.0    C     2016-10-25 12:10:00   \n",
      "2      Crucero 2016     37.0    C     2016-10-25 12:10:00   \n",
      "3      Crucero 2016     37.0    C     2016-10-25 12:10:00   \n",
      "4      Crucero 2016     37.0    C     2016-10-25 12:10:00   \n",
      "...             ...      ...  ...                     ...   \n",
      "25098  Crucero 2018     25.0    C     2018-07-23 21:53:00   \n",
      "25099  Crucero 2018     25.0    C     2018-07-23 21:53:00   \n",
      "25100  Crucero 2018     25.0    C     2018-07-23 21:53:00   \n",
      "25101  Crucero 2018     25.0    C     2018-07-23 21:53:00   \n",
      "25102  Crucero 2018     25.0    C     2018-07-23 21:53:00   \n",
      "\n",
      "       longitude_degrees_east  latitude_degrees_north  bot_depth_m ship  \\\n",
      "0                    73.05760                46.17430        270.0   A1   \n",
      "1                    73.05760                46.17430        270.0   A1   \n",
      "2                    73.05760                46.17430        270.0   A1   \n",
      "3                    73.05760                46.17430        270.0   A1   \n",
      "4                    73.05760                46.17430        270.0   A1   \n",
      "...                       ...                     ...          ...  ...   \n",
      "25098                73.44286                46.43094        310.0   A1   \n",
      "25099                73.44286                46.43094        310.0   A1   \n",
      "25100                73.44286                46.43094        310.0   A1   \n",
      "25101                73.44286                46.43094        310.0   A1   \n",
      "25102                73.44286                46.43094        310.0   A1   \n",
      "\n",
      "       depth_m  fluorescence_wet_labs_eco_afl_fl_mg_m_3  \\\n",
      "0        0.497                                      0.0   \n",
      "1        1.010                                      0.0   \n",
      "2        1.516                                      0.0   \n",
      "3        2.012                                      0.0   \n",
      "4        2.523                                      0.0   \n",
      "...        ...                                      ...   \n",
      "25098  298.000                                      0.0   \n",
      "25099  298.500                                      0.0   \n",
      "25100  299.000                                      0.0   \n",
      "25101  299.500                                      0.0   \n",
      "25102  300.000                                      0.0   \n",
      "\n",
      "       dissolved_oxygen_ml_l  temperature_deg_c  salinity_practical_psu  \n",
      "0                    6.88523             7.3546                 30.7609  \n",
      "1                    6.90105             7.2775                 30.6860  \n",
      "2                    6.90176             7.2760                 30.6708  \n",
      "3                    6.90315             7.2617                 30.6780  \n",
      "4                    6.90701             7.2311                 30.6943  \n",
      "...                      ...                ...                     ...  \n",
      "25098                6.71186             7.7706                 33.2114  \n",
      "25099                6.71206             7.7694                 33.2115  \n",
      "25100                6.71197             7.7698                 33.2114  \n",
      "25101                6.71229             7.7673                 33.2123  \n",
      "25102                6.71302             7.7637                 33.2131  \n",
      "\n",
      "[25100 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Arreglamos los nombres de las columnas\n",
    "df = standardise_column_names(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             cruise  station type yyyy_mm_ddthh_mm_ss_sss  \\\n",
      "0      Crucero 2016     37.0    C     2016-10-25 12:10:00   \n",
      "1      Crucero 2016     37.0    C     2016-10-25 12:10:00   \n",
      "2      Crucero 2016     37.0    C     2016-10-25 12:10:00   \n",
      "3      Crucero 2016     37.0    C     2016-10-25 12:10:00   \n",
      "4      Crucero 2016     37.0    C     2016-10-25 12:10:00   \n",
      "...             ...      ...  ...                     ...   \n",
      "25098  Crucero 2018     25.0    C     2018-07-23 21:53:00   \n",
      "25099  Crucero 2018     25.0    C     2018-07-23 21:53:00   \n",
      "25100  Crucero 2018     25.0    C     2018-07-23 21:53:00   \n",
      "25101  Crucero 2018     25.0    C     2018-07-23 21:53:00   \n",
      "25102  Crucero 2018     25.0    C     2018-07-23 21:53:00   \n",
      "\n",
      "       longitude_degrees_east  latitude_degrees_north  bot_depth_m ship  id  \n",
      "0                    73.05760                46.17430        270.0   A1   0  \n",
      "1                    73.05760                46.17430        270.0   A1   0  \n",
      "2                    73.05760                46.17430        270.0   A1   0  \n",
      "3                    73.05760                46.17430        270.0   A1   0  \n",
      "4                    73.05760                46.17430        270.0   A1   0  \n",
      "...                       ...                     ...          ...  ...  ..  \n",
      "25098                73.44286                46.43094        310.0   A1  58  \n",
      "25099                73.44286                46.43094        310.0   A1  58  \n",
      "25100                73.44286                46.43094        310.0   A1  58  \n",
      "25101                73.44286                46.43094        310.0   A1  58  \n",
      "25102                73.44286                46.43094        310.0   A1  58  \n",
      "\n",
      "[25100 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# Agrupamos por las variables del viaje en id y creamos df2 sin variables de las mediciones.\n",
    "df[\"id\"] = df.groupby(df[['cruise', 'ship', 'station', 'yyyy_mm_ddthh_mm_ss_sss',\n",
    "                          'longitude_degrees_east', 'latitude_degrees_north', 'bot_depth_m']]\n",
    "                      .apply(frozenset, axis=1)).ngroup()\n",
    "\n",
    "df2 = df.drop(['depth_m', 'fluorescence_wet_labs_eco_afl_fl_mg_m_3',\n",
    "               'dissolved_oxygen_ml_l', 'temperature_deg_c', 'salinity_practical_psu'],\n",
    "              axis=1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       depth_m  fluorescence_wet_labs_eco_afl_fl_mg_m_3  \\\n",
      "0        0.497                                      0.0   \n",
      "1        1.010                                      0.0   \n",
      "2        1.516                                      0.0   \n",
      "3        2.012                                      0.0   \n",
      "4        2.523                                      0.0   \n",
      "...        ...                                      ...   \n",
      "25098  298.000                                      0.0   \n",
      "25099  298.500                                      0.0   \n",
      "25100  299.000                                      0.0   \n",
      "25101  299.500                                      0.0   \n",
      "25102  300.000                                      0.0   \n",
      "\n",
      "       dissolved_oxygen_ml_l  temperature_deg_c  salinity_practical_psu  id  \n",
      "0                    6.88523             7.3546                 30.7609   0  \n",
      "1                    6.90105             7.2775                 30.6860   0  \n",
      "2                    6.90176             7.2760                 30.6708   0  \n",
      "3                    6.90315             7.2617                 30.6780   0  \n",
      "4                    6.90701             7.2311                 30.6943   0  \n",
      "...                      ...                ...                     ...  ..  \n",
      "25098                6.71186             7.7706                 33.2114  58  \n",
      "25099                6.71206             7.7694                 33.2115  58  \n",
      "25100                6.71197             7.7698                 33.2114  58  \n",
      "25101                6.71229             7.7673                 33.2123  58  \n",
      "25102                6.71302             7.7637                 33.2131  58  \n",
      "\n",
      "[25100 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Creamos df3 con variables de las mediciones y con id que linkea tablas en formato 1 a muchos\n",
    "# donde 1 es en df2\n",
    "df3 = df.drop(['cruise', 'ship', 'station', 'type', 'yyyy_mm_ddthh_mm_ss_sss',\n",
    "              'longitude_degrees_east', 'latitude_degrees_north', 'bot_depth_m'], axis=1)\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  depth_m                                 variable     value\n",
      "0        0    0.497  fluorescence_wet_labs_eco_afl_fl_mg_m_3   0.00000\n",
      "1        0    0.497                    dissolved_oxygen_ml_l   6.88523\n",
      "2        0    0.497                        temperature_deg_c   7.35460\n",
      "3        0    0.497                   salinity_practical_psu  30.76090\n",
      "4        0    1.010  fluorescence_wet_labs_eco_afl_fl_mg_m_3   0.00000\n",
      "...     ..      ...                                      ...       ...\n",
      "100395  58  299.500                   salinity_practical_psu  33.21230\n",
      "100396  58  300.000  fluorescence_wet_labs_eco_afl_fl_mg_m_3   0.00000\n",
      "100397  58  300.000                    dissolved_oxygen_ml_l   6.71302\n",
      "100398  58  300.000                        temperature_deg_c   7.76370\n",
      "100399  58  300.000                   salinity_practical_psu  33.21310\n",
      "\n",
      "[100400 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Stackeamos las variables con llaves id y depth\n",
    "df4 = df3.set_index(['id', 'depth_m'])\n",
    "df4 = df4.stack().rename_axis(['id', 'depth_m', 'variable']).rename('value').reset_index()\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crucero 2018    9830\n",
      "Crucero 2016    7774\n",
      "Crucero 2017    7496\n",
      "Name: cruise, dtype: int64\n",
      "El crusero de 2018 tiene mas datos\n"
     ]
    }
   ],
   "source": [
    "# Obtenemos los datos de cruseros por a単o\n",
    "print(df['cruise'].value_counts())\n",
    "print('El crusero de 2018 tiene mas datos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22    2789\n",
      "14    2199\n",
      "20    2156\n",
      "12    1991\n",
      "21    1691\n",
      "17    1505\n",
      "02    1325\n",
      "16    1277\n",
      "23    1248\n",
      "08    1218\n",
      "03    1156\n",
      "09    1099\n",
      "06     967\n",
      "04     731\n",
      "13     690\n",
      "11     537\n",
      "19     534\n",
      "10     404\n",
      "07     400\n",
      "01     394\n",
      "00     346\n",
      "05     226\n",
      "15     217\n",
      "Name: time, dtype: int64\n",
      " La hora con mayor cantidad de datos es 14:51:00 \n"
     ]
    }
   ],
   "source": [
    "# Obtenemos los datos de las horas agrupandolas\n",
    "f = df\n",
    "f['time'] = df['yyyy_mm_ddthh_mm_ss_sss'].dt.strftime('%H')\n",
    "print(f['time'].value_counts())\n",
    "print(' Las 22 horas poseen la mayor cantidad de datos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El promedio de las variables por profundidad es: \n",
      "               depth_m  fluorescence_wet_labs_eco_afl_fl_mg_m_3  \\\n",
      "depth_m                                                           \n",
      "(0, 10]       5.188698                                 0.000876   \n",
      "(10, 20]     15.136645                                 0.005172   \n",
      "(20, 30]     25.165145                                 0.000000   \n",
      "(30, 40]     35.193853                                 0.000000   \n",
      "(40, 50]     45.222678                                 0.000000   \n",
      "(50, 60]     55.155023                                 0.000000   \n",
      "(60, 70]     65.122051                                 0.000000   \n",
      "(70, 80]     75.151827                                 0.000000   \n",
      "(80, 90]     85.181785                                 0.000000   \n",
      "(90, 100]    95.211847                                 0.000000   \n",
      "(100, 110]  105.118456                                 0.000000   \n",
      "(110, 120]  115.039443                                 0.000000   \n",
      "(120, 130]  125.106330                                 0.000000   \n",
      "(130, 140]  135.165258                                 0.000000   \n",
      "(140, 150]  145.156709                                 0.000000   \n",
      "(150, 160]  155.146849                                 0.000000   \n",
      "(160, 170]  165.090151                                 0.000000   \n",
      "(170, 180]  175.065470                                 0.000000   \n",
      "(180, 190]  185.108701                                 0.000000   \n",
      "(190, 200]  195.115835                                 0.000000   \n",
      "(200, 210]  204.893368                                 0.000000   \n",
      "(210, 220]  215.112984                                 0.000000   \n",
      "(220, 230]  225.101913                                 0.000000   \n",
      "(230, 240]  235.075526                                 0.000000   \n",
      "(240, 250]  245.025682                                 0.000000   \n",
      "(250, 260]  255.085305                                 0.000000   \n",
      "(260, 270]  264.960159                                 0.000000   \n",
      "(270, 280]  275.182285                                 0.000000   \n",
      "(280, 290]  285.203505                                 0.000000   \n",
      "(290, 300]  295.224215                                 0.000000   \n",
      "(300, 310]  305.002989                                 0.000000   \n",
      "(310, 320]  315.126357                                 0.000000   \n",
      "(320, 330]  325.159172                                 0.000000   \n",
      "(330, 340]  334.791669                                 0.000000   \n",
      "(340, 350]  345.229300                                 0.000000   \n",
      "(350, 360]  355.202424                                 0.000000   \n",
      "(360, 370]  365.171610                                 0.000000   \n",
      "(370, 380]  374.962741                                 0.000000   \n",
      "(380, 390]  385.048629                                 0.000000   \n",
      "(390, 400]  394.886946                                 0.000000   \n",
      "(400, 410]  405.250000                                 0.000000   \n",
      "(410, 420]  415.023810                                 0.000000   \n",
      "(420, 430]  425.250000                                 0.000000   \n",
      "(430, 440]  435.250000                                 0.000000   \n",
      "(440, 450]  445.250000                                 0.000000   \n",
      "(450, 460]  455.250000                                 0.000000   \n",
      "(460, 470]  465.250000                                 0.000000   \n",
      "(470, 480]  475.250000                                 0.000000   \n",
      "(480, 490]  485.250000                                 0.000000   \n",
      "\n",
      "            dissolved_oxygen_ml_l  temperature_deg_c  salinity_practical_psu  \n",
      "depth_m                                                                       \n",
      "(0, 10]                  7.089759           6.076352               30.877987  \n",
      "(10, 20]                 7.059245           6.197621               31.081131  \n",
      "(20, 30]                 7.039193           6.287326               31.184612  \n",
      "(30, 40]                 7.016051           6.392231               31.306129  \n",
      "(40, 50]                 6.977364           6.571705               31.510242  \n",
      "(50, 60]                 6.931490           6.797522               31.718105  \n",
      "(60, 70]                 6.877127           7.078846               31.934342  \n",
      "(70, 80]                 6.828360           7.342476               32.105839  \n",
      "(80, 90]                 6.795907           7.517303               32.228044  \n",
      "(90, 100]                6.767914           7.669285               32.337273  \n",
      "(100, 110]               6.744323           7.798530               32.429897  \n",
      "(110, 120]               6.724557           7.898819               32.534128  \n",
      "(120, 130]               6.719895           7.914154               32.589680  \n",
      "(130, 140]               6.713521           7.940041               32.644606  \n",
      "(140, 150]               6.707450           7.962494               32.702859  \n",
      "(150, 160]               6.700049           7.998137               32.746583  \n",
      "(160, 170]               6.696120           8.012236               32.785773  \n",
      "(170, 180]               6.696699           8.004425               32.798929  \n",
      "(180, 190]               6.694630           8.010926               32.822626  \n",
      "(190, 200]               6.691360           8.026056               32.842782  \n",
      "(200, 210]               6.683203           8.069187               32.876242  \n",
      "(210, 220]               6.672218           8.122129               32.939521  \n",
      "(220, 230]               6.665433           8.153026               32.982083  \n",
      "(230, 240]               6.660896           8.175301               33.007125  \n",
      "(240, 250]               6.643023           8.269508               33.086118  \n",
      "(250, 260]               6.634211           8.328772               33.086065  \n",
      "(260, 270]               6.641940           8.279218               33.080165  \n",
      "(270, 280]               6.652052           8.214652               33.070314  \n",
      "(280, 290]               6.653384           8.204394               33.074620  \n",
      "(290, 300]               6.653491           8.202474               33.078711  \n",
      "(300, 310]               6.640803           8.281662               33.096176  \n",
      "(310, 320]               6.617244           8.400401               33.218523  \n",
      "(320, 330]               6.618216           8.397096               33.207165  \n",
      "(330, 340]               6.616504           8.402996               33.227086  \n",
      "(340, 350]               6.616155           8.405354               33.227750  \n",
      "(350, 360]               6.617205           8.398486               33.227349  \n",
      "(360, 370]               6.619827           8.380959               33.227635  \n",
      "(370, 380]               6.630702           8.307898               33.227109  \n",
      "(380, 390]               6.659757           8.113816               33.220408  \n",
      "(390, 400]               6.666321           8.072498               33.211316  \n",
      "(400, 410]               6.675050           8.024955               33.175225  \n",
      "(410, 420]               6.653886           8.182395               33.116548  \n",
      "(420, 430]               6.654591           8.178865               33.111970  \n",
      "(430, 440]               6.655917           8.169470               33.113950  \n",
      "(440, 450]               6.656092           8.167970               33.115160  \n",
      "(450, 460]               6.656213           8.166950               33.115850  \n",
      "(460, 470]               6.656798           8.162560               33.117560  \n",
      "(470, 480]               6.657232           8.159085               33.119520  \n",
      "(480, 490]               6.657725           8.155715               33.119825  \n"
     ]
    }
   ],
   "source": [
    "# Obtenemos variables segun rango de profundidad.\n",
    "print('El promedio de las variables por profundidad es: ')\n",
    "print(df3.groupby(pd.cut(df3[\"depth_m\"], np.arange(0, 500, 10))).mean().drop('id', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El promedio de las variables por a単os es: \n",
      "              fluorescence_wet_labs_eco_afl_fl_mg_m_3  dissolved_oxygen_ml_l  \\\n",
      "cruise                                                                         \n",
      "Crucero 2016                                 0.000129               6.803122   \n",
      "Crucero 2017                                 0.000000               6.782033   \n",
      "Crucero 2018                                 0.000610               6.822331   \n",
      "\n",
      "              temperature_deg_c  salinity_practical_psu  \n",
      "cruise                                                   \n",
      "Crucero 2016           7.425740               32.385250  \n",
      "Crucero 2017           7.651004               32.161600  \n",
      "Crucero 2018           7.362178               32.247831  \n"
     ]
    }
   ],
   "source": [
    "# Obtenemos variables segun a単o a traves de agrupar por crusero.\n",
    "X = df.groupby(df['cruise']).mean()\n",
    "print('El promedio de las variables por a単os es: ')\n",
    "print(X[['fluorescence_wet_labs_eco_afl_fl_mg_m_3', 'dissolved_oxygen_ml_l',\n",
    "         'temperature_deg_c', 'salinity_practical_psu']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
